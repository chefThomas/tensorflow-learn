# Chapter 1: What is AI

## What is Intelligence?

- intelligence was outside the realm of mechanical structures until advent of computers.
- 1950s: AI term coined
- `AI`: imitation of human activities that we believe requires intelligence, regardless of sophistication. Even losing tic-tac-toe algorithm can be called AI

## History of AI

- Previously AI at a high-level was a collection of if-then statements
- Machine Learning (ML): an application trained according to data fed to it
- `von Neuman bottleneck`
  - limitation on data flow from memory to CPU imposed by traditional computer architecture.
  - 2000s: overcome by graphics processing units (GPU)
- ML jumped from academia to reality with one of the first ML milestones: `image recognition`, specifically, reading handwritten digits.
  - Hinton used ML` deep neural networks`

## `Neural Networks`

- digital `nodes` (aka `perceptron networks`) simulate neurons
  - activate like synapses
- Vastly layered connectioned of nodes --> `deep learning`
- AI is the super set
  - Machine Learning
    - Deep learning
- Training `iterations` are used to build out neurons based on data --> predictive power increases i.e. the model learns
- We learn through electrical signals induced by stimuli. In ML, the analog is `tensor`.

## Today's AI

- 2015, AI begins outperforming humans in some tasks
  - lawyering
  - cancer detection from x-ray films
- Applications:
  - music, writing, visual content
  - recommending content
  - deduce laws from data
  - visual classification and identifiers

## Why TensorFlow?

- Supported by Google
- supports optimized and tested GPU-boosted code
- online ready
  - can run Tensorflow directly from the browser importing libraries from Google
- offline ready
  - can save the code to a device like a PWA so apps can run without an internet connection
  - speed and cost advantage

| Browser       | Server | Mobile            | Desktop       | IoT          |
| ------------- | ------ | ----------------- | ------------- | ------------ |
| Most browsers | Node   | React Native, PWA | Electron, PWA | Raspberry Pi |

## Types of Machine Learning

### Supervised

- most common form of ML
- uses an 'answer key' of labeled data to train our machine
- Examples
  - image categorization
  - natural language processing (NLP)
  - Image segmentation

### Unsupervised

- Focus on what a machine can learn and report from unlabeled data
- E.g., how many groups of something exist, like plant species in a garden

### Semisupervised

- at least some of the data are labeled
- Generative Adversarial Networks (GAN) like Dall-E
  - trained on examples using semisupervised methods and output is a new example.

### Reinforcement

- Providing a reward for actions when they produce desirable outcomes reinforces the 'correct' actions.
- used in Mario speed runs

## What do Frameworks Provide

- in ML, the models write the algorithms, not the programmer. The programmer writes the trainer with the help of a framework. The algorithm + tuning = model is the output
  - outline parameters
  - define structure
  - location of training data
  - run the training program
    - output is an algorithm that balances the structure defined by the programmer. Algorithms are essentially a collection of numbers associated with a graph, which we collectively call a model.
- We use TensorFlow.js to specify model architecture, load data, and tune the model to improve predictive power.

## What Is a Model and How Do Neural Networks Learn?

- Neural network is an encoded graph with intelligently chosen, randomized values for each neuron
- The first prediction made is as far away from correct as pure random chance, because it hasn't been trained
- After iterating (learning), neural network weights are evaluated and adjusted
- After training, the model can be used to make predictions by feeding it data. A probabilistic results is the output.
